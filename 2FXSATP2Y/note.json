{
  "paragraphs": [
    {
      "text": "%md\n# About This Lab\n**Objective:** Become familiar with dataframes schemas operations.\nCreate and save DataFrames using different types of data sources. \nLearn options for inferring and defining schemas.\n**File locations:**\n    Exercise files: /home/training/training_materials/devsh/exercises/dataframes\n    Data (local): /home/training/training_materials/devsh/data/devices.json\n    Data (HDFS): /devsh_loudacre/devices.json\n    Hive table: devsh.accounts\n**Successful outcome:**\n**Before you begin:**\n**Related lessons:** Working with Dataframes and Schemas\n\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.670",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eAbout This Lab\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eObjective:\u003c/strong\u003e Become familiar with dataframes schemas operations.\n\u003cbr  /\u003eCreate and save DataFrames using different types of data sources.\n\u003cbr  /\u003eLearn options for inferring and defining schemas.\n\u003cbr  /\u003e\u003cstrong\u003eFile locations:\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eExercise files: /home/training/training_materials/devsh/exercises/dataframes\nData (local): /home/training/training_materials/devsh/data/devices.json\nData (HDFS): /devsh_loudacre/devices.json\nHive table: devsh.accounts\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSuccessful outcome:\u003c/strong\u003e\n\u003cbr  /\u003e\u003cstrong\u003eBefore you begin:\u003c/strong\u003e\n\u003cbr  /\u003e\u003cstrong\u003eRelated lessons:\u003c/strong\u003e Working with Dataframes and Schemas\u003c/p\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930670_1509659423",
      "id": "20171105-200834_1116095891",
      "dateCreated": "2021-02-02 08:35:30.670",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Setup\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.670",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eSetup\u003c/h1\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930670_-742666331",
      "id": "20181114-164229_902436001",
      "dateCreated": "2021-02-02 08:35:30.670",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Delete existing HDFS files to prevent file exists errors",
      "text": "%sh\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/accounts_zip94913\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.670",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "rm: `/devsh_loudacre/accounts_zip94913\u0027: No such file or directory\n"
          },
          {
            "type": "TEXT",
            "data": "ExitValue: 1"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930670_-1997888501",
      "id": "20210122-182625_537679893",
      "dateCreated": "2021-02-02 08:35:30.670",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Environment variable required to use SetJobGroup",
      "text": "%sh\n\nPYSPARK_PIN_THREAD\u003dtrue",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.670",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930670_1086768183",
      "id": "20200830-073644_1484939052",
      "dateCreated": "2021-02-02 08:35:30.670",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Retrieve the Spark Context",
      "text": "%pyspark\n\nsc \u003d spark.sparkContext",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.671",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cfont color\u003d\"red\"\u003ePrevious livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!\u003c/font\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930670_865237538",
      "id": "20200830-074054_2080534068",
      "dateCreated": "2021-02-02 08:35:30.670",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Lab\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.671",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eLab\u003c/h1\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930671_1188142628",
      "id": "20181114-164844_1661453681",
      "dateCreated": "2021-02-02 08:35:30.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Create a Dataframe Based on a Hive Table",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.671",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eCreate a Dataframe Based on a Hive Table\u003c/h3\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930671_-42874267",
      "id": "20171105-200519_752831754",
      "dateCreated": "2021-02-02 08:35:30.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe %sql magic provides you with a Spark SQL environment that allows you to interact with Hive tables.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.671",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eThe %sql magic provides you with a Spark SQL environment that allows you to interact with Hive tables.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930671_1089320861",
      "id": "20181115-084123_1911813743",
      "dateCreated": "2021-02-02 08:35:30.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "1 - Review the schema of the devsh.accounts table",
      "text": "%sql",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.671",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930671_-405821269",
      "id": "20171105-200623_656362182",
      "dateCreated": "2021-02-02 08:35:30.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "2 - Create a new DataFrame using the Hive devsh.accounts table",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.679",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930671_-1083943526",
      "id": "20171105-201709_849284875",
      "dateCreated": "2021-02-02 08:35:30.679",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPrint the schema and the first 10 rows of the DataFrame, and note that the schema aligns with that of the Hive table.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.679",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003ePrint the schema and the first 10 rows of the DataFrame, and note that the schema aligns with that of the Hive table.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930679_1548087989",
      "id": "20171105-201449_1118165660",
      "dateCreated": "2021-02-02 08:35:30.679",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "3 - View the dataframe and confirm alignment with the Hive table",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.679",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930679_-1206968060",
      "id": "20200111-175746_198257135",
      "dateCreated": "2021-02-02 08:35:30.679",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a new DataFrame with rows from the accounts data where the zip code is 94913, and save the result to CSV files in the /devsh_loudacre/ accounts_zip94913 HDFS directory. \nYou can do this in a single command, as shown below, or with multiple commands.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.679",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a new DataFrame with rows from the accounts data where the zip code is 94913, and save the result to CSV files in the /devsh_loudacre/ accounts_zip94913 HDFS directory.\n\u003cbr  /\u003eYou can do this in a single command, as shown below, or with multiple commands.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930679_-1005087216",
      "id": "20200111-180055_1261073848",
      "dateCreated": "2021-02-02 08:35:30.679",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "4 - Create a new dataframe and save it to HDFS",
      "text": "%pyspark",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930679_214147413",
      "id": "20200111-180152_647295647",
      "dateCreated": "2021-02-02 08:35:30.679",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nUse hdfs to view the /devsh_loudacre/accounts_zip94913 directory in HDFS and the data in one of the saved files.\nConfirm that the CSV file includes a header line, and that only records for the selected zip code are included.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eUse hdfs to view the /devsh_loudacre/accounts_zip94913 directory in HDFS and the data in one of the saved files.\n\u003cbr  /\u003eConfirm that the CSV file includes a header line, and that only records for the selected zip code are included.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-157892048",
      "id": "20200111-180517_2057464815",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "5 - Confirm successful write to HDFS",
      "text": "%sh\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-1129168588",
      "id": "20200111-180616_878429565",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Optional: \nTry creating a new DataFrame based on the CSV files you created above. \nCompare the schema of the original accountsDF and the new DataFrame. What’s different? \nTry again, this time setting the inferSchema option to true and compare again.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eOptional:\u003c/h3\u003e\n\u003cp\u003eTry creating a new DataFrame based on the CSV files you created above.\n\u003cbr  /\u003eCompare the schema of the original accountsDF and the new DataFrame. What’s different?\n\u003cbr  /\u003eTry again, this time setting the inferSchema option to true and compare again.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-1749439488",
      "id": "20200111-181226_903550862",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "6 - Optional: study the impact of the inferSchema option",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_1320959462",
      "id": "20200111-181420_1328402570",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Define a Schema for a DataFrame\nIf you have not done so yet, review the data in the HDFS file /devsh_loudacre/devices.json.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eDefine a Schema for a DataFrame\u003c/h3\u003e\n\u003cp\u003eIf you have not done so yet, review the data in the HDFS file /devsh_loudacre/devices.json.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-1092380712",
      "id": "20200111-182630_966116104",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "7 - Review the data in /devsh_loudacre/devices.json",
      "text": "%sh\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-1399164663",
      "id": "20200111-182913_1175240105",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a new DataFrame based on the devices.json file. (This command could take several seconds while it infers the schema.)",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a new DataFrame based on the devices.json file. (This command could take several seconds while it infers the schema.)\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_1687531466",
      "id": "20200111-183241_1034944500",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "8 - Read the devices.json file into a devDF dataframe",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_1563330087",
      "id": "20200111-183151_1635217379",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nView the schema of the devDF DataFrame. Note the column names and types that Spark inferred from the JSON file. \nIn particular, note that the release_dt column is of type string, whereas the data in the column actually represents a timestamp.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eView the schema of the devDF DataFrame. Note the column names and types that Spark inferred from the JSON file.\n\u003cbr  /\u003eIn particular, note that the release_dt column is of type string, whereas the data in the column actually represents a timestamp.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_1320068678",
      "id": "20200111-183538_253681976",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "9 - View the schema of the devDF dataframe",
      "text": "%pyspark",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.680",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930680_-423035245",
      "id": "20200111-183606_516389013",
      "dateCreated": "2021-02-02 08:35:30.680",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nDefine a schema that correctly specifies the column types for this DataFrame. \nStart by importing the package with the definitions of necessary classes and types.\nNext, create a collection of StructField objects, which represent column definitions. \nThe release_dt column should be a timestamp.\n\n```spark\nfrom pyspark.sql.types import *\ndevColumns \u003d [ StructField(\"devnum\",LongType()), StructField(\"make\",StringType()), StructField(\"model\",StringType()), StructField(\"release_dt\",TimestampType()), StructField(\"dev_type\",StringType())]\n```",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eDefine a schema that correctly specifies the column types for this DataFrame.\n\u003cbr  /\u003eStart by importing the package with the definitions of necessary classes and types.\n\u003cbr  /\u003eNext, create a collection of StructField objects, which represent column definitions.\n\u003cbr  /\u003eThe release_dt column should be a timestamp.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"spark\"\u003efrom pyspark.sql.types import *\ndevColumns \u003d [ StructField(\"devnum\",LongType()), StructField(\"make\",StringType()), StructField(\"model\",StringType()), StructField(\"release_dt\",TimestampType()), StructField(\"dev_type\",StringType())]\n\u003c/code\u003e\u003c/pre\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_-1346507990",
      "id": "20200111-185637_433874821",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "10 - Define a schema",
      "text": "%pyspark\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_1189980072",
      "id": "20200111-185741_1002287600",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "11 - Create a schema (a StructType object) using the column definition list",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_1082055880",
      "id": "20200111-190339_1337771160",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "12 - Recreate the devDF DataFrame, this time using the new schema",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_1807456039",
      "id": "20200111-190529_818511213",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "13 - View the schema and data of the new DataFrame, and confirm that the release_dt column type is now timestamp",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_1380170220",
      "id": "20200111-190751_1912942450",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow that the device data uses the correct schema, write the data into Parquet format, which automatically embeds the schema. \nSave the Parquet data files into an HDFS directory called /devsh_loudacre/devices_parquet.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eNow that the device data uses the correct schema, write the data into Parquet format, which automatically embeds the schema.\n\u003cbr  /\u003eSave the Parquet data files into an HDFS directory called /devsh_loudacre/devices_parquet.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_492746412",
      "id": "20200111-191615_1691108697",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "14 - Save the devDF dataframe to /devsh_loudacre/devices_parquet using the parquet format",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_-183251190",
      "id": "20200111-191643_697955659",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Optional: \n\nUse parquet-tools to view the schema of the saved files. First download the HDFS directory (or an individual file), then run the command.\n\n```shell\n$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/ \n$ parquet-tools schema /tmp/devices_parquet/\n```\n\nIn CDH 5, the parquet-tools command could be used directly on files in HDFS. In CDH 6, this is no longer the case. \nAs a workaround, you can use: hadoop jar /opt/cloudera/parcels/CDH/jars/parquet-tools-1.9.0- cdh6.1.1.jar schema hdfs://localhost/devsh_loudacre/devices_parquet/. Related JIRA: CDH-80574.\n\nNote that the type of the release_dt column is noted as int96; this is how Spark denotes a timestamp type in Parquet.\nFor more information about parquet-tools, run parquet-tools --help.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eOptional:\u003c/h3\u003e\n\u003cp\u003eUse parquet-tools to view the schema of the saved files. First download the HDFS directory (or an individual file), then run the command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"shell\"\u003e$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/ \n$ parquet-tools schema /tmp/devices_parquet/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn CDH 5, the parquet-tools command could be used directly on files in HDFS. In CDH 6, this is no longer the case.\n\u003cbr  /\u003eAs a workaround, you can use: hadoop jar /opt/cloudera/parcels/CDH/jars/parquet-tools-1.9.0- cdh6.1.1.jar schema hdfs://localhost/devsh_loudacre/devices_parquet/. Related JIRA: CDH-80574.\u003c/p\u003e\n\u003cp\u003eNote that the type of the release_dt column is noted as int96; this is how Spark denotes a timestamp type in Parquet.\n\u003cbr  /\u003eFor more information about parquet-tools, run parquet-tools \u0026ndash;help.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_1099527814",
      "id": "20200111-192204_1182605032",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "15 - Optional - Confirm the schema of the saved files using parquet-tools",
      "text": "%sh",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_-1218395565",
      "id": "20200111-192641_1103008129",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a new DataFrame using the Parquet files you saved in devices_parquet and view its schema.\nNote that Spark is able to correctly infer the timestamp type of the release_dt column from Parquet’s embedded schema.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.681",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a new DataFrame using the Parquet files you saved in devices_parquet and view its schema.\n\u003cbr  /\u003eNote that Spark is able to correctly infer the timestamp type of the release_dt column from Parquet’s embedded schema.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_536299205",
      "id": "20200111-193044_783469452",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "16 - Optional - Read the parquet files back in a dataframe to confirm the schema is well saved",
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930681_2047420372",
      "id": "20200111-193146_2016640957",
      "dateCreated": "2021-02-02 08:35:30.681",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Result\n**You have now:** explored different methods to define the schema of a dataframe.\n\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eResult\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eYou have now:\u003c/strong\u003e explored different methods to define the schema of a dataframe.\u003c/p\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-1743481813",
      "id": "20181119-142716_792318228",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Solution\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eSolution\u003c/h1\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-1926032819",
      "id": "20171113-155535_1769142099",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Create a Dataframe Based on a Hive Table",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eCreate a Dataframe Based on a Hive Table\u003c/h3\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-1663838712",
      "id": "20210122-190017_1915525627",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "1 - Review the schema of the devsh.accounts table",
      "text": "%sql\n\nDESCRIBE devsh.accounts",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "col_name": "string",
                      "data_type": "string",
                      "comment": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "col_name\tdata_type\tcomment\nacct_num\tint\tnull\nacct_create_dt\ttimestamp\tnull\nacct_close_dt\ttimestamp\tnull\nfirst_name\tstring\tnull\nlast_name\tstring\tnull\naddress\tstring\tnull\ncity\tstring\tnull\nstate\tstring\tnull\nzipcode\tstring\tnull\nphone_number\tstring\tnull\ncreated\ttimestamp\tnull\nmodified\ttimestamp\tnull"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-1268164046",
      "id": "20200111-173912_1607664098",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe Livy interprepter provides you with a Spark SQL environment that allows you directly to interact with Hive tables.\nThe %sql provides a SQL like environment allowing straight SQL commands.\n\nThis exercise usess a DataFrame based on the `account` table in the Hive database. \n\nHive beeline CLI\nbeeline -u jdbc:hive2://localhost:10000 -e \"DESCRIBE devsh.accounts\"\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eThe Livy interprepter provides you with a Spark SQL environment that allows you directly to interact with Hive tables.\n\u003cbr  /\u003eThe %sql provides a SQL like environment allowing straight SQL commands.\u003c/p\u003e\n\u003cp\u003eThis exercise usess a DataFrame based on the \u003ccode\u003eaccount\u003c/code\u003e table in the Hive database.\u003c/p\u003e\n\u003cp\u003eHive beeline CLI\n\u003cbr  /\u003ebeeline -u jdbc:hive2://localhost:10000 -e \u0026ldquo;DESCRIBE devsh.accounts\u0026rdquo;\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-966319801",
      "id": "20210121-130036_113149906",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "2 - Create a new DataFrame using the Hive devsh.accounts table",
      "text": "%pyspark\n\naccountsDF \u003d spark.read.table(\"devsh.accounts\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_1728723131",
      "id": "20200111-175424_830219293",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe `table` function uses a jdbc connection to locates the Hive metastore to pull\nin schema information from the hive RDBMS database. This also passes the connect\nstring for HiveServer2 to the Spark driver. \n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eThe \u003ccode\u003etable\u003c/code\u003e function uses a jdbc connection to locates the Hive metastore to pull\n\u003cbr  /\u003ein schema information from the hive RDBMS database. This also passes the connect\n\u003cbr  /\u003estring for HiveServer2 to the Spark driver.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_1166647823",
      "id": "20210122-182010_1298352692",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "3 - View the dataframe and confirm alignment with the Hive table",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Show the accounts data\")\naccountsDF.printSchema()\naccountsDF.show(10)",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.682",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "acct_num": "string",
                      "acct_create_dt": "string",
                      "acct_close_dt": "string",
                      "first_name": "string",
                      "last_name": "string",
                      "address": "string",
                      "city": "string",
                      "state": "string",
                      "zipcode": "string",
                      "phone_number": "string",
                      "created": "string",
                      "modified": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- acct_num: integer (nullable \u003d true)\n |-- acct_create_dt: timestamp (nullable \u003d true)\n |-- acct_close_dt: timestamp (nullable \u003d true)\n |-- first_name: string (nullable \u003d true)\n |-- last_name: string (nullable \u003d true)\n |-- address: string (nullable \u003d true)\n |-- city: string (nullable \u003d true)\n |-- state: string (nullable \u003d true)\n |-- zipcode: string (nullable \u003d true)\n |-- phone_number: string (nullable \u003d true)\n |-- created: timestamp (nullable \u003d true)\n |-- modified: timestamp (nullable \u003d true)\n\n+--------+-------------------+-------------------+----------+---------+--------------------+-------------+-----+-------+------------+-------------------+-------------------+\n|acct_num|     acct_create_dt|      acct_close_dt|first_name|last_name|             address|         city|state|zipcode|phone_number|            created|           modified|\n+--------+-------------------+-------------------+----------+---------+--------------------+-------------+-----+-------+------------+-------------------+-------------------+\n|       1|2008-10-23 16:05:05|               null|    Donald|   Becton|2275 Washburn Street|      Oakland|   CA|  94660|  5100032418|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       2|2008-11-12 03:00:01|               null|     Donna|    Jones| 3885 Elliott Street|San Francisco|   CA|  94171|  4150835799|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       3|2008-12-21 09:19:50|               null|    Dorthy| Chalmers|    4073 Whaley Lane|    San Mateo|   CA|  94479|  6506877757|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       4|2008-11-28 00:08:09|               null|     Leila|  Spencer|    1447 Ross Street|    San Mateo|   CA|  94444|  6503198619|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       5|2008-11-15 23:06:06|               null|     Anita| Laughlin|    2767 Hill Street|     Richmond|   CA|  94872|  5107754354|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       6|2008-11-20 12:39:33|2014-03-01 07:37:48|    Stevie|   Bridge|   3977 Linda Street|   Sacramento|   CA|  94264|  9162111862|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       7|2008-12-09 10:32:12|2010-10-16 10:01:51|     David|   Eggers|    2109 Ross Street|      Oakland|   CA|  94508|  5103935529|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       8|2008-12-15 08:49:38|               null|   Dorothy|  Koopman|   1985 Pratt Avenue|    San Mateo|   CA|  94469|  6502406661|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|       9|2008-11-07 17:58:55|2014-02-14 01:26:52|      Kara|     Kohl|     235 Fort Street|    Palo Alto|   CA|  94312|  6502384894|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|      10|2008-12-02 23:28:01|               null|     Diane|   Nelson|      921 Sardis Sta|      Oakland|   CA|  94577|  5102711264|2014-03-18 13:29:47|2014-03-18 13:29:47|\n+--------+-------------------+-------------------+----------+---------+--------------------+-------------+-----+-------+------------+-------------------+-------------------+\nonly showing top 10 rows"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930682_-1002137713",
      "id": "20200111-175849_1440047182",
      "dateCreated": "2021-02-02 08:35:30.682",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPrint the schema and the first 10 rows of the DataFrame. Compare that the Dataframe schema \naligns with that of the Hive table.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.683",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003ePrint the schema and the first 10 rows of the DataFrame. Compare that the Dataframe schema\n\u003cbr  /\u003ealigns with that of the Hive table.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930683_86318507",
      "id": "20210121-134836_1444803397",
      "dateCreated": "2021-02-02 08:35:30.683",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "4 - Create a new dataframe and save it to HDFS",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Write the filtered accounts data\")\naccountsDF.where(\"zipcode \u003d 94913\").write.option(\"header\",\"true\").csv(\"/devsh_loudacre/accounts_zip94913\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.683",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930683_-589807615",
      "id": "20200111-180302_674401673",
      "dateCreated": "2021-02-02 08:35:30.683",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nThe `where` function is used to select rows. \n\nThe `write` function is used to write data from Spark to HDFS. Spark will write to a large number of data formats.\nCommon data types include: .avro, .csv, .json, and .text\n\nThe `option` function will pass in parameters; such as `header` \u003d true, to include the schema on the first row.\n\nCreate a new DataFrame with rows from the accounts data where the zip code is 94913, and save the result \nto CSV files in the /devsh_loudacre/ accounts_zip94913 HDFS directory.\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.689",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eThe \u003ccode\u003ewhere\u003c/code\u003e function is used to select rows.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003ewrite\u003c/code\u003e function is used to write data from Spark to HDFS. Spark will write to a large number of data formats.\n\u003cbr  /\u003eCommon data types include: .avro, .csv, .json, and .text\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003eoption\u003c/code\u003e function will pass in parameters; such as \u003ccode\u003eheader\u003c/code\u003e \u003d true, to include the schema on the first row.\u003c/p\u003e\n\u003cp\u003eCreate a new DataFrame with rows from the accounts data where the zip code is 94913, and save the result\n\u003cbr  /\u003eto CSV files in the /devsh_loudacre/ accounts_zip94913 HDFS directory.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930683_67665080",
      "id": "20210121-140054_655193673",
      "dateCreated": "2021-02-02 08:35:30.683",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "5 - Confirm successful write to HDFS",
      "text": "%sh\n\nhdfs dfs -ls /devsh_loudacre/accounts_zip94913\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.689",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Found 5 items\n-rw-r--r--   3 livy supergroup          0 2021-01-22 18:28 /devsh_loudacre/accounts_zip94913/_SUCCESS\n-rw-r--r--   3 livy supergroup        973 2021-01-22 18:28 /devsh_loudacre/accounts_zip94913/part-00000-a8e14485-51ec-47dc-83ae-dbf06ef7fd79-c000.csv\n-rw-r--r--   3 livy supergroup       1134 2021-01-22 18:28 /devsh_loudacre/accounts_zip94913/part-00001-a8e14485-51ec-47dc-83ae-dbf06ef7fd79-c000.csv\n-rw-r--r--   3 livy supergroup       1425 2021-01-22 18:28 /devsh_loudacre/accounts_zip94913/part-00002-a8e14485-51ec-47dc-83ae-dbf06ef7fd79-c000.csv\n-rw-r--r--   3 livy supergroup       1676 2021-01-22 18:28 /devsh_loudacre/accounts_zip94913/part-00003-a8e14485-51ec-47dc-83ae-dbf06ef7fd79-c000.csv\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930689_348961218",
      "id": "20200111-180700_593022127",
      "dateCreated": "2021-02-02 08:35:30.689",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nhdfs dfs -cat /devsh_loudacre/accounts_zip94913/part-0000*",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.689",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "acct_num,acct_create_dt,acct_close_dt,first_name,last_name,address,city,state,zipcode,phone_number,created,modified\n19,2008-11-13T23:40:53.000-08:00,2014-02-26T18:44:26.000-08:00,Leona,Bray,364 Romrog Way,Santa Rosa,CA,94913,7070013038,2014-03-18T13:29:47.000-07:00,2014-03-18T13:29:47.000-07:00\n3156,2009-07-03T11:04:35.000-07:00,\"\",Stephen,Bisson,1116 Daylene Drive,Santa Rosa,CA,94913,7075647641,2014-03-18T13:29:53.000-07:00,2014-03-18T13:29:53.000-07:00\n5536,2010-05-15T14:09:32.000-07:00,\"\",Steven,Jones,4818 Copperhead Road,Santa Rosa,CA,94913,7079211079,2014-03-18T13:29:57.000-07:00,2014-03-18T13:29:57.000-07:00\n6320,2010-09-22T01:35:25.000-07:00,\"\",Victor,Cheatham,2564 Center Avenue,Santa Rosa,CA,94913,7078711417,2014-03-18T13:29:59.000-07:00,2014-03-18T13:29:59.000-07:00\n19938,2011-06-22T02:18:05.000-07:00,2014-01-27T22:10:49.000-08:00,David,Reeves,2971 Biddie Lane,Santa Rosa,CA,94913,7071048775,2014-03-18T13:30:23.000-07:00,2014-03-18T13:30:23.000-07:00\nacct_num,acct_create_dt,acct_close_dt,first_name,last_name,address,city,state,zipcode,phone_number,created,modified\n33877,2012-07-09T10:27:41.000-07:00,\"\",Bobby,Allen,1847 Geneva Street,Santa Rosa,CA,94913,7071386791,2014-03-18T13:30:48.000-07:00,2014-03-18T13:30:48.000-07:00\n40376,2012-06-03T03:19:42.000-07:00,2013-12-13T14:19:21.000-08:00,Anna,Soo,1167 Front Street,Santa Rosa,CA,94913,7070584229,2014-03-18T13:31:00.000-07:00,2014-03-18T13:31:00.000-07:00\n43505,2012-10-08T21:40:36.000-07:00,\"\",Karin,Macias,706 Parrish Avenue,Santa Rosa,CA,94913,7076549760,2014-03-18T13:31:06.000-07:00,2014-03-18T13:31:06.000-07:00\n45913,2012-10-22T05:36:30.000-07:00,2014-01-19T01:26:10.000-08:00,Paul,Nguyen,4258 Wilkinson Street,Santa Rosa,CA,94913,7078891627,2014-03-18T13:31:13.000-07:00,2014-03-18T13:31:13.000-07:00\n54686,2012-09-27T08:02:47.000-07:00,\"\",Donald,Ivory,4477 Kelly Street,Santa Rosa,CA,94913,7075033458,2014-03-18T13:31:31.000-07:00,2014-03-18T13:31:31.000-07:00\n54883,2012-08-24T23:45:53.000-07:00,\"\",James,Kost,1912 Hanifan Lane,Santa Rosa,CA,94913,7072786836,2014-03-18T13:31:31.000-07:00,2014-03-18T13:31:31.000-07:00\nacct_num,acct_create_dt,acct_close_dt,first_name,last_name,address,city,state,zipcode,phone_number,created,modified\n65566,2012-12-13T05:57:14.000-08:00,\"\",Leroy,Chisolm,3063 Still Pastures Drive,Santa Rosa,CA,94913,7073226063,2014-03-18T13:31:54.000-07:00,2014-03-18T13:31:54.000-07:00\n66420,2012-01-03T23:48:12.000-08:00,\"\",Edwin,Frison,4542 Viking Drive,Santa Rosa,CA,94913,7075442930,2014-03-18T13:31:55.000-07:00,2014-03-18T13:31:55.000-07:00\n67313,2012-09-11T11:07:02.000-07:00,\"\",Phyllis,Hairston,3954 Lynch Street,Santa Rosa,CA,94913,7070726914,2014-03-18T13:31:57.000-07:00,2014-03-18T13:31:57.000-07:00\n77509,2013-01-26T18:11:58.000-08:00,\"\",Christine,Foster,634 Pointe Lane,Santa Rosa,CA,94913,7078692081,2014-03-18T13:32:15.000-07:00,2014-03-18T13:32:15.000-07:00\n82268,2013-07-19T18:10:24.000-07:00,\"\",Barbara,Johnson,773 Green Street,Santa Rosa,CA,94913,7072606527,2014-03-18T13:32:24.000-07:00,2014-03-18T13:32:24.000-07:00\n92139,2013-10-21T18:54:43.000-07:00,\"\",Hollis,Weaver,3636 Timber Oak Drive,Santa Rosa,CA,94913,7076909568,2014-03-18T13:32:41.000-07:00,2014-03-18T13:32:41.000-07:00\n92976,2013-03-06T22:46:53.000-08:00,\"\",William,Valez,4704 Marie Street,Santa Rosa,CA,94913,7078645626,2014-03-18T13:32:43.000-07:00,2014-03-18T13:32:43.000-07:00\n94751,2013-06-04T23:52:42.000-07:00,\"\",Althea,Ward,546 Rainbow Road,Santa Rosa,CA,94913,7074846196,2014-03-18T13:32:46.000-07:00,2014-03-18T13:32:46.000-07:00\nacct_num,acct_create_dt,acct_close_dt,first_name,last_name,address,city,state,zipcode,phone_number,created,modified\n101477,2013-03-29T23:08:30.000-07:00,\"\",Brenda,Newman,1015 Butternut Lane,Santa Rosa,CA,94913,7077409845,2014-03-18T13:32:58.000-07:00,2014-03-18T13:32:58.000-07:00\n104648,2013-05-20T14:05:01.000-07:00,2014-01-29T07:18:03.000-08:00,Denise,Strunk,278 Red Bud Lane,Santa Rosa,CA,94913,7074883275,2014-03-18T13:33:04.000-07:00,2014-03-18T13:33:04.000-07:00\n105949,2013-06-15T21:07:51.000-07:00,\"\",Robert,Nee,3137 Heliport Loop,Santa Rosa,CA,94913,7076332623,2014-03-18T13:33:07.000-07:00,2014-03-18T13:33:07.000-07:00\n110212,2013-11-19T18:34:28.000-08:00,\"\",Marion,Moore,4044 Hamilton Drive,Santa Rosa,CA,94913,7076758301,2014-03-18T13:33:14.000-07:00,2014-03-18T13:33:14.000-07:00\n110547,2013-11-02T07:36:51.000-07:00,\"\",Glenda,Powell,1439 Burton Avenue,Santa Rosa,CA,94913,7072120889,2014-03-18T13:33:15.000-07:00,2014-03-18T13:33:15.000-07:00\n116688,2013-11-24T11:33:02.000-08:00,2014-03-03T10:59:07.000-08:00,Michael,Stevenson,4032 Oakwood Avenue,Santa Rosa,CA,94913,7076071590,2014-03-18T13:33:26.000-07:00,2014-03-18T13:33:26.000-07:00\n126602,2014-02-14T03:55:05.000-08:00,2014-03-08T05:24:58.000-08:00,Sara,Quinones,1502 Stanton Hollow Road,Santa Rosa,CA,94913,7078061393,2014-03-18T13:33:44.000-07:00,2014-03-18T13:33:44.000-07:00\n127094,2014-01-07T14:12:08.000-08:00,\"\",Evelyn,Thomas,717 East Avenue,Santa Rosa,CA,94913,7071495566,2014-03-18T13:33:45.000-07:00,2014-03-18T13:33:45.000-07:00\n128177,2014-01-01T07:06:09.000-08:00,\"\",David,Campbell,4565 Lynn Avenue,Santa Rosa,CA,94913,7079187489,2014-03-18T13:33:46.000-07:00,2014-03-18T13:33:46.000-07:00\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930689_855438420",
      "id": "20210122-182843_1309430737",
      "dateCreated": "2021-02-02 08:35:30.689",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nUse hdfs to view the /devsh_loudacre/accounts_zip94913 directory in HDFS and the data in one of the saved files.\nCopy and paste one of the files from account_zip94913 directory into the hdfs dfs -head command.\nConfirm that the CSV file includes a header line, and that only records for the selected zip code are included.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.689",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eUse hdfs to view the /devsh_loudacre/accounts_zip94913 directory in HDFS and the data in one of the saved files.\n\u003cbr  /\u003eCopy and paste one of the files from account_zip94913 directory into the hdfs dfs -head command.\n\u003cbr  /\u003eConfirm that the CSV file includes a header line, and that only records for the selected zip code are included.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930689_863747834",
      "id": "20210121-140625_1512204011",
      "dateCreated": "2021-02-02 08:35:30.689",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "6 - Optional: study the impact of the inferSchema option",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read a csv file: no options\")\nspark.read.csv(\"/devsh_loudacre/accounts_zip94913\").printSchema()\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read a csv file: header\u003dtrue\")\nspark.read.option(\"header\",\"true\").csv(\"/devsh_loudacre/accounts_zip94913\").printSchema()\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read a csv file: header\u003dtrue inferSchema\u003dtrue\")\nspark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/devsh_loudacre/accounts_zip94913\").printSchema()",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.689",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- _c0: string (nullable \u003d true)\n |-- _c1: string (nullable \u003d true)\n |-- _c2: string (nullable \u003d true)\n |-- _c3: string (nullable \u003d true)\n |-- _c4: string (nullable \u003d true)\n |-- _c5: string (nullable \u003d true)\n |-- _c6: string (nullable \u003d true)\n |-- _c7: string (nullable \u003d true)\n |-- _c8: string (nullable \u003d true)\n |-- _c9: string (nullable \u003d true)\n |-- _c10: string (nullable \u003d true)\n |-- _c11: string (nullable \u003d true)\n\nroot\n |-- acct_num: string (nullable \u003d true)\n |-- acct_create_dt: string (nullable \u003d true)\n |-- acct_close_dt: string (nullable \u003d true)\n |-- first_name: string (nullable \u003d true)\n |-- last_name: string (nullable \u003d true)\n |-- address: string (nullable \u003d true)\n |-- city: string (nullable \u003d true)\n |-- state: string (nullable \u003d true)\n |-- zipcode: string (nullable \u003d true)\n |-- phone_number: string (nullable \u003d true)\n |-- created: string (nullable \u003d true)\n |-- modified: string (nullable \u003d true)\n\nroot\n |-- acct_num: integer (nullable \u003d true)\n |-- acct_create_dt: timestamp (nullable \u003d true)\n |-- acct_close_dt: timestamp (nullable \u003d true)\n |-- first_name: string (nullable \u003d true)\n |-- last_name: string (nullable \u003d true)\n |-- address: string (nullable \u003d true)\n |-- city: string (nullable \u003d true)\n |-- state: string (nullable \u003d true)\n |-- zipcode: integer (nullable \u003d true)\n |-- phone_number: long (nullable \u003d true)\n |-- created: timestamp (nullable \u003d true)\n |-- modified: timestamp (nullable \u003d true)"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930689_-1107154464",
      "id": "20200111-182021_1532001378",
      "dateCreated": "2021-02-02 08:35:30.689",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNo options assigns an alphanumeric sequence to all fields and casts all fields as data type string.\n\nHeader \u003d true will assign field names but will cast all fields as data type string.\n\nHeader \u003d true, Infer Schema \u003d true will assign filed names and assign data types. \n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eNo options assigns an alphanumeric sequence to all fields and casts all fields as data type string.\u003c/p\u003e\n\u003cp\u003eHeader \u003d true will assign field names but will cast all fields as data type string.\u003c/p\u003e\n\u003cp\u003eHeader \u003d true, Infer Schema \u003d true will assign filed names and assign data types.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930689_-746659399",
      "id": "20210122-183034_1388155243",
      "dateCreated": "2021-02-02 08:35:30.689",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Define a Schema for a DataFrame\nIf you have not done so yet, review the data in the HDFS file /devsh_loudacre/devices.json\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eDefine a Schema for a DataFrame\u003c/h3\u003e\n\u003cp\u003eIf you have not done so yet, review the data in the HDFS file /devsh_loudacre/devices.json\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_288760180",
      "id": "20210122-190110_2062914929",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "7 - Review the data in /devsh_loudacre/devices.json",
      "text": "%sh\n\nhdfs dfs -head /devsh_loudacre/devices.json",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "{\"devnum\":1,\"release_dt\":\"2008-10-21T00:00:00.000-07:00\",\"make\":\"Sorrento\",\"model\":\"F00L\",\"dev_type\":\"phone\"}\n{\"devnum\":2,\"release_dt\":\"2010-04-19T00:00:00.000-07:00\",\"make\":\"Titanic\",\"model\":\"2100\",\"dev_type\":\"phone\"}\n{\"devnum\":3,\"release_dt\":\"2011-02-18T00:00:00.000-08:00\",\"make\":\"MeeToo\",\"model\":\"3.0\",\"dev_type\":\"phone\"}\n{\"devnum\":4,\"release_dt\":\"2011-09-21T00:00:00.000-07:00\",\"make\":\"MeeToo\",\"model\":\"3.1\",\"dev_type\":\"phone\"}\n{\"devnum\":5,\"release_dt\":\"2008-10-21T00:00:00.000-07:00\",\"make\":\"iFruit\",\"model\":\"1\",\"dev_type\":\"phone\"}\n{\"devnum\":6,\"release_dt\":\"2011-11-02T00:00:00.000-07:00\",\"make\":\"iFruit\",\"model\":\"3\",\"dev_type\":\"phone\"}\n{\"devnum\":7,\"release_dt\":\"2010-05-20T00:00:00.000-07:00\",\"make\":\"iFruit\",\"model\":\"2\",\"dev_type\":\"phone\"}\n{\"devnum\":8,\"release_dt\":\"2013-07-02T00:00:00.000-07:00\",\"make\":\"iFruit\",\"model\":\"5\",\"dev_type\":\"phone\"}\n{\"devnum\":9,\"release_dt\":\"2008-10-21T00:00:00.000-07:00\",\"make\":\"Titanic\",\"model\":\"1000\",\"dev_type\":\"phone\"}\n{\"devnum\":10,\"release_dt\":\"2008-10-21T00:00:00.000-07:00\",\"mak"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_1384036729",
      "id": "20200111-183034_19858163",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "8 - Read the devices.json file into a devDF dataframe",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read the devices.json file\")\ndevDF \u003d spark.read.json(\"/devsh_loudacre/devices.json\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_-342298800",
      "id": "20200111-183406_507235503",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a new DataFrame based on the devices.json file. (This command could take several seconds while it infers the schema.)\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a new DataFrame based on the devices.json file. (This command could take several seconds while it infers the schema.)\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_1027030581",
      "id": "20210121-140752_339312179",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "9- View the schema of the devDF dataframe",
      "text": "%pyspark\n\ndevDF.printSchema()\ndevDF.show(5)",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- devnum: long (nullable \u003d true)\n |-- make: string (nullable \u003d true)\n |-- model: string (nullable \u003d true)\n |-- release_dt: timestamp (nullable \u003d true)\n |-- dev_type: string (nullable \u003d true)\n\n+------+--------+-----+-------------------+--------+\n|devnum|    make|model|         release_dt|dev_type|\n+------+--------+-----+-------------------+--------+\n|     1|Sorrento| F00L|2008-10-21 00:00:00|   phone|\n|     2| Titanic| 2100|2010-04-19 00:00:00|   phone|\n|     3|  MeeToo|  3.0|2011-02-18 00:00:00|   phone|\n|     4|  MeeToo|  3.1|2011-09-21 00:00:00|   phone|\n|     5|  iFruit|    1|2008-10-21 00:00:00|   phone|\n+------+--------+-----+-------------------+--------+\nonly showing top 5 rows"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_439535048",
      "id": "20200111-185504_2076885456",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nView the schema of the `devDF` DataFrame. Note the column names and types that Spark inferred from the \nJSON file. In particular, note that the `release_dt` column is of type `string`, whereas the data in \nthe column actually represents a timestamp.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eView the schema of the \u003ccode\u003edevDF\u003c/code\u003e DataFrame. Note the column names and types that Spark inferred from the\n\u003cbr  /\u003eJSON file. In particular, note that the \u003ccode\u003erelease_dt\u003c/code\u003e column is of type \u003ccode\u003estring\u003c/code\u003e, whereas the data in\n\u003cbr  /\u003ethe column actually represents a timestamp.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_464576895",
      "id": "20210121-142717_1842020453",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "10 - Define a schema",
      "text": "%pyspark\n\nfrom pyspark.sql.types import *\n\ndevColumns \u003d [ \n    StructField(\"devnum\",LongType()), \n    StructField(\"make\",StringType()), \n    StructField(\"model\",StringType()), \n    StructField(\"release_dt\",TimestampType()), \n    StructField(\"dev_type\",StringType())\n    ]\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.690",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930690_669540805",
      "id": "20200111-190012_576363507",
      "dateCreated": "2021-02-02 08:35:30.690",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nDefine a schema that correctly specifies the data types for each column of this DataFrame. \n\nStart by importing the package with the definitions of necessary classes and types.\n\nA `StructField` object is used to define the field name and the data type.\nA schema is defined as a collection of `StructFields`.\n\nNext, create a collection of `StructField` objects, which represent column definitions. \nThe `release_dt` column should be a timestamp.\n\n```spark\nfrom pyspark.sql.types import *\ndevColumns \u003d [ StructField(\"devnum\",LongType()), StructField(\"make\",StringType()), StructField(\"model\",StringType()), StructField(\"release_dt\",TimestampType()), StructField(\"dev_type\",StringType())]\n```\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.691",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eDefine a schema that correctly specifies the data types for each column of this DataFrame.\u003c/p\u003e\n\u003cp\u003eStart by importing the package with the definitions of necessary classes and types.\u003c/p\u003e\n\u003cp\u003eA \u003ccode\u003eStructField\u003c/code\u003e object is used to define the field name and the data type.\n\u003cbr  /\u003eA schema is defined as a collection of \u003ccode\u003eStructFields\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eNext, create a collection of \u003ccode\u003eStructField\u003c/code\u003e objects, which represent column definitions.\n\u003cbr  /\u003eThe \u003ccode\u003erelease_dt\u003c/code\u003e column should be a timestamp.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"spark\"\u003efrom pyspark.sql.types import *\ndevColumns \u003d [ StructField(\"devnum\",LongType()), StructField(\"make\",StringType()), StructField(\"model\",StringType()), StructField(\"release_dt\",TimestampType()), StructField(\"dev_type\",StringType())]\n\u003c/code\u003e\u003c/pre\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930691_1337229767",
      "id": "20210121-140904_185066472",
      "dateCreated": "2021-02-02 08:35:30.691",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "11 - Create a schema (a StructType object) using the column definition list",
      "text": "%pyspark\n\ndevSchema \u003d StructType(devColumns)",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_1122489067",
      "id": "20200111-190405_1345983159",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a schema (a `StructType` object) using the column definition list.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a schema (a \u003ccode\u003eStructType\u003c/code\u003e object) using the column definition list.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_478174246",
      "id": "20210121-143155_1071743868",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "12 - Recreate the devDF DataFrame, this time using the new schema",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read the devices.json file with a schema\")\ndevDF \u003d spark.read.schema(devSchema).json(\"/devsh_loudacre/devices.json\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_562710233",
      "id": "20200111-190932_1097085748",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "13 - View the schema and data of the new DataFrame, and confirm that the release_dt column type is now timestamp",
      "text": "%pyspark\n\ndevDF.printSchema()\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Show the devices DataFrame\")\ndevDF.show(5)",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "devnum": "string",
                      "make": "string",
                      "model": "string",
                      "release_dt": "string",
                      "dev_type": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- devnum: long (nullable \u003d true)\n |-- make: string (nullable \u003d true)\n |-- model: string (nullable \u003d true)\n |-- release_dt: timestamp (nullable \u003d true)\n |-- dev_type: string (nullable \u003d true)\n\n+------+--------+-----+-------------------+--------+\n|devnum|    make|model|         release_dt|dev_type|\n+------+--------+-----+-------------------+--------+\n|     1|Sorrento| F00L|2008-10-21 00:00:00|   phone|\n|     2| Titanic| 2100|2010-04-19 00:00:00|   phone|\n|     3|  MeeToo|  3.0|2011-02-18 00:00:00|   phone|\n|     4|  MeeToo|  3.1|2011-09-21 00:00:00|   phone|\n|     5|  iFruit|    1|2008-10-21 00:00:00|   phone|\n+------+--------+-----+-------------------+--------+\nonly showing top 5 rows"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_810546130",
      "id": "20200111-190849_1182876565",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nView the schema and data of the new DataFrame, and confirm that the `release_dt` column type is \nnow of type `timestamp`.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eView the schema and data of the new DataFrame, and confirm that the \u003ccode\u003erelease_dt\u003c/code\u003e column type is\n\u003cbr  /\u003enow of type \u003ccode\u003etimestamp\u003c/code\u003e.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_-1777983936",
      "id": "20210121-143308_2141220186",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "14 - Save the devDF dataframe to /devsh_loudacre/devices_parquet using the parquet format",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Write the devices DataFrame in parquet format\")\ndevDF.write.parquet(\"/devsh_loudacre/devices_parquet\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_-373565229",
      "id": "20200111-191831_2119240237",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNow that the device data uses the correct schema, write the data into Parquet format, which automatically embeds the schema. \nSave the Parquet data files into an HDFS directory called /devsh_loudacre/devices_parquet.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.700",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eNow that the device data uses the correct schema, write the data into Parquet format, which automatically embeds the schema.\n\u003cbr  /\u003eSave the Parquet data files into an HDFS directory called /devsh_loudacre/devices_parquet.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930700_333984910",
      "id": "20210121-141421_1547432313",
      "dateCreated": "2021-02-02 08:35:30.700",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "15 - Optional - Confirm the schema of the saved files using parquet-tools",
      "text": "%sh\n\nhdfs dfs -get /devsh_loudacre/devices_parquet /tmp/\nparquet-tools schema /tmp/devices_parquet/",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "get: `/tmp/devices_parquet/_SUCCESS\u0027: File exists\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize\u003d512m; support was removed in 8.0\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize\u003d512m; support was removed in 8.0\nmessage spark_schema {\n  optional int64 devnum;\n  optional binary make (STRING);\n  optional binary model (STRING);\n  optional int96 release_dt;\n  optional binary dev_type (STRING);\n}\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_1996224479",
      "id": "20200111-192819_852011514",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Optional\n\nUse `parquet-tools` to view the schema of the saved files. First download the HDFS directory (or an individual file), then run the command.\n\n```shell\n$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/ \n$ parquet-tools schema /tmp/devices_parquet/\n```\n\nIn CDH 5, the parquet-tools command could be used directly on files in HDFS. In CDH 6, this is no longer the case. \nAs a workaround, you can use: hadoop jar /opt/cloudera/parcels/CDH/jars/parquet-tools-1.9.0- cdh6.1.1.jar schema hdfs://localhost/devsh_loudacre/devices_parquet/. Related JIRA: CDH-80574.\n\nNote that the type of the `release_dt` column is noted as `int96`; this is how Spark denotes a timestamp type in Parquet.\nFor more information about `parquet-tools`, run `parquet-tools --help`.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eOptional\u003c/h3\u003e\n\u003cp\u003eUse \u003ccode\u003eparquet-tools\u003c/code\u003e to view the schema of the saved files. First download the HDFS directory (or an individual file), then run the command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"shell\"\u003e$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/ \n$ parquet-tools schema /tmp/devices_parquet/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn CDH 5, the parquet-tools command could be used directly on files in HDFS. In CDH 6, this is no longer the case.\n\u003cbr  /\u003eAs a workaround, you can use: hadoop jar /opt/cloudera/parcels/CDH/jars/parquet-tools-1.9.0- cdh6.1.1.jar schema hdfs://localhost/devsh_loudacre/devices_parquet/. Related JIRA: CDH-80574.\u003c/p\u003e\n\u003cp\u003eNote that the type of the \u003ccode\u003erelease_dt\u003c/code\u003e column is noted as \u003ccode\u003eint96\u003c/code\u003e; this is how Spark denotes a timestamp type in Parquet.\n\u003cbr  /\u003eFor more information about \u003ccode\u003eparquet-tools\u003c/code\u003e, run \u003ccode\u003eparquet-tools --help\u003c/code\u003e.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_-674726292",
      "id": "20210121-141607_1157000296",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "16 - Optional - Read the parquet files back in a dataframe to confirm the schema is well saved",
      "text": "%pyspark\n\nsc.setJobGroup(\"Working with DataFrames and schemas\",\"Read the devices DataFrame in parquet format\")\nspark.read.parquet(\"/devsh_loudacre/devices_parquet\").printSchema()",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- devnum: long (nullable \u003d true)\n |-- make: string (nullable \u003d true)\n |-- model: string (nullable \u003d true)\n |-- release_dt: timestamp (nullable \u003d true)\n |-- dev_type: string (nullable \u003d true)"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_1451438430",
      "id": "20200111-193316_622744995",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCreate a new DataFrame using the Parquet files you saved in devices_parquet and view its schema.\nNote that Spark is able to correctly infer the timestamp type of the release_dt column from Parquet’s embedded schema.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eCreate a new DataFrame using the Parquet files you saved in devices_parquet and view its schema.\n\u003cbr  /\u003eNote that Spark is able to correctly infer the timestamp type of the release_dt column from Parquet’s embedded schema.\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_-1791210434",
      "id": "20210121-141733_613796356",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Tear Down\n---",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch1\u003eTear Down\u003c/h1\u003e\n\u003chr /\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_1920655550",
      "id": "20200830-075248_1182047608",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Delete the Livy session",
      "text": "%sh\n\nsessionId\u003d$(curl -s localhost:8998/sessions | jq \u0027.sessions[0].id\u0027)\ncurl -s localhost:8998/sessions/$sessionId -X DELETE",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "{\"msg\":\"deleted\"}"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_818976219",
      "id": "20200830-075258_565376786",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Additional resources",
      "text": "%md\nWe hope you\u0027ve enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.701",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 10.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cp\u003eWe hope you\u0027ve enjoyed this lab. Below are additional resources that you should find useful:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href\u003d\"http://cloudera.com/tutorials.html\"\u003eCloudera Tutorials\u003c/a\u003e are your natural next step where you can explore Spark in more depth.\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"https://community.cloudera.com\"\u003eCloudera Community\u003c/a\u003e is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"https://spark.apache.org/documentation.html\"\u003eApache Spark Documentation\u003c/a\u003e - official Spark documentation.\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"https://zeppelin.apache.org\"\u003eApache Zeppelin Project Home Page\u003c/a\u003e - official Zeppelin web site.\u003c/li\u003e\n\u003c/ol\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930701_1173071513",
      "id": "20181116-135131_93712280",
      "dateCreated": "2021-02-02 08:35:30.701",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%angular\n\u003c/br\u003e\n\u003c/br\u003e\n\u003c/br\u003e\n\u003c/br\u003e\n\u003ccenter\u003e\n\u003ca href\u003d\"https://www.cloudera.com/about/training/courses.html\"\u003e\n  \u003cimg src\u003d\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt\u003d\"Cloudera University\" style\u003d\"width:280px;height:40px;border:0;\" align\u003d\"middle\"\u003e\n\u003c/a\u003e\n\u003c/center\u003e\n\u003c/br\u003e\n\u003c/br\u003e",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.707",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 2.0,
        "editorMode": "ace/mode/undefined",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "ANGULAR",
            "data": "\u003c/br\u003e\n\u003c/br\u003e\n\u003c/br\u003e\n\u003c/br\u003e\n\u003ccenter\u003e\n\u003ca href\u003d\"https://www.cloudera.com/about/training/courses.html\"\u003e\n  \u003cimg src\u003d\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt\u003d\"Cloudera University\" style\u003d\"width:280px;height:40px;border:0;\" align\u003d\"middle\"\u003e\n\u003c/a\u003e\n\u003c/center\u003e\n\u003c/br\u003e\n\u003c/br\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1612254930707_778643151",
      "id": "20200110-154537_1406191376",
      "dateCreated": "2021-02-02 08:35:30.707",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%angular\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-02 08:35:30.707",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1612254930707_-1570435772",
      "id": "20200110-162013_302547143",
      "dateCreated": "2021-02-02 08:35:30.707",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "~Trash/DevSH/Labs/Pyspark/WorkingWithDataframes",
  "id": "2FXSATP2Y",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}